{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do imports just once and for all\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import json\n",
    "\n",
    "#instead of popup, plot images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test Daten (dictionary) \n",
    "docs = {    \n",
    "    'file1': ['ein','test','für','Dokument','eins'],    \n",
    "    'file2': ['ein','weiteres','Dokument'],\n",
    "    'file3': ['alle','guten','Dinge','sind','drei']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing load and save\n",
    "# - Numpy Arrays: https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html\n",
    "# - General: \n",
    "#   - Input/Output: https://docs.python.org/3.3/tutorial/inputoutput.html\n",
    "#   - Write JSON Dump: http://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file-in-python\n",
    "\n",
    "#import json\n",
    "with open('files/test.dict', 'w+') as outfile:\n",
    "    json.dump(docs, outfile)\n",
    "\n",
    "with open('files/test.dict', 'r') as infile:\n",
    "    docs2 = json.load(infile)\n",
    "    \n",
    "docs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://datascience.blog.wzb.eu/2016/06/17/creating-a-sparse-document-term-matrix-for-topic-modeling-via-lda/\n",
    "# -> adapted to fit TermxDoc Matrix without additional transpose at the end\n",
    "\n",
    "#Init Vocabulary (Set)\n",
    "vocab = set()\n",
    "\n",
    "#Init Count of Non-Zero Values\n",
    "n_nonzero = 0\n",
    "\n",
    "#Iterate over documents an create vocabulary\n",
    "for docterms in docs.values():\n",
    "    unique_terms = set(docterms)    # all unique terms of this doc (set of terms)\n",
    "    vocab |= unique_terms           # set union: add unique terms of this doc\n",
    "    n_nonzero += len(unique_terms)  # increase Non-Zero count by adding count of unique terms in this doc\n",
    "    \n",
    "\n",
    "#convert to numpy for processing\n",
    "docpaths = np.array(list(docs.keys())) # keys of dictionary (order of dictionary is used, but this doesn't correspond to order of inserts!)\n",
    "vocab = np.array(list(vocab)) \n",
    "\n",
    "#Array containing sorted indices\n",
    "vocab_sorter = np.argsort(vocab)   \n",
    "\n",
    "#print(vocab_sorter) #sorted indizes \n",
    "#print(vocab[vocab_sorter]) #outputs sorted vocabulary\n",
    "\n",
    "ndocs = len(docpaths)\n",
    "nvocab = len(vocab)\n",
    "\n",
    "#Initialize components of COO-Matrix (values, row indizes, col indizes) with emtpy values (for all non-zero elements)\n",
    "data = np.empty(n_nonzero, dtype=np.intc)     # all non-zero term frequencies at data[i,k]\n",
    "rows = np.empty(n_nonzero, dtype=np.intc)     # row index for [i,k]th data item (ith term freq.)\n",
    "cols = np.empty(n_nonzero, dtype=np.intc)     # column index for [i,k]th data item (kth document)\n",
    "\n",
    "#Init index (w.r.t. position in arrays of sparse COO matrix)\n",
    "ind = 0     \n",
    "# go through all documents with their terms\n",
    "for docpath, terms in docs.items():\n",
    "    # find indices into  such that, if the corresponding elements in  were\n",
    "    # inserted before the indices, the order of  would be preserved\n",
    "    # -> array of indices of  in \n",
    "    term_indices = vocab_sorter[np.searchsorted(vocab, terms, sorter=vocab_sorter)]\n",
    "\n",
    "    # count the unique terms of the document and get their vocabulary indices\n",
    "    uniq_indices, counts = np.unique(term_indices, return_counts=True)\n",
    "    n_vals = len(uniq_indices)  # = number of unique terms\n",
    "    ind_end = ind + n_vals  #  to  is the slice that we will fill with data\n",
    "\n",
    "    data[ind:ind_end] = counts                  # save the counts (term frequencies)\n",
    "    rows[ind:ind_end] = uniq_indices            # save the row index: index in \n",
    "    doc_idx = np.where(docpaths == docpath)     # get the document index for the document name\n",
    "    cols[ind:ind_end] = np.repeat(doc_idx, n_vals)  # save it as repeated value\n",
    "\n",
    "    ind = ind_end  # resume with next document -> add data to the end\n",
    "    \n",
    "dtm = coo_matrix((data, (rows, cols)), shape=(nvocab, ndocs), dtype=np.intc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [0 1 0]]\n",
      "['für' 'sind' 'Dokument' 'Dinge' 'alle' 'eins' 'weiteres' 'drei' 'guten'\n",
      " 'ein' 'test']\n",
      "['file2' 'file1' 'file3']\n"
     ]
    }
   ],
   "source": [
    "print(dtm.toarray())\n",
    "print(vocab)\n",
    "print(docpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
