{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do imports just once and for all\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.linalg import inv, norm\n",
    "import math\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "#instead of popup, plot images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test Daten (dictionary) \n",
    "docs = {    \n",
    "    'file1': ['ein','test','für','Dokument','eins'],    \n",
    "    'file21': ['ein','weiteres','Dokument'],\n",
    "    'file22': ['ein','weiteres','Dokument'],\n",
    "    'file3': ['alle','guten','Dinge','sind','drei'],\n",
    "    'file4': ['ein','test','für','Dokument','drei'], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing load and save\n",
    "# - Numpy Arrays: https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html\n",
    "# - General: \n",
    "#   - Input/Output: https://docs.python.org/3.3/tutorial/inputoutput.html\n",
    "#   - Write JSON Dump: http://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file-in-python\n",
    "\n",
    "#import json\n",
    "with open('files/test.dict', 'w+') as outfile:\n",
    "    json.dump(docs, outfile)\n",
    "\n",
    "with open('files/test.dict', 'r') as infile:\n",
    "    docs2 = json.load(infile)\n",
    "    \n",
    "docs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://datascience.blog.wzb.eu/2016/06/17/creating-a-sparse-document-term-matrix-for-topic-modeling-via-lda/\n",
    "# -> adapted to fit TermxDoc Matrix without additional transpose at the end\n",
    "\n",
    "#Init Vocabulary (Set)\n",
    "vocab = set()\n",
    "\n",
    "#Init Count of Non-Zero Values\n",
    "n_nonzero = 0\n",
    "\n",
    "#Iterate over documents an create vocabulary\n",
    "for docterms in docs.values():\n",
    "    unique_terms = set(docterms)    # all unique terms of this doc (set of terms)\n",
    "    vocab |= unique_terms           # set union: add unique terms of this doc\n",
    "    n_nonzero += len(unique_terms)  # increase Non-Zero count by adding count of unique terms in this doc\n",
    "    \n",
    "\n",
    "#convert to numpy for processing\n",
    "docpaths = np.array(list(docs.keys())) # keys of dictionary (order of dictionary is used, but this doesn't correspond to order of inserts!)\n",
    "vocab = np.array(list(vocab)) \n",
    "\n",
    "#Array containing sorted indices\n",
    "vocab_sorter = np.argsort(vocab)   \n",
    "\n",
    "#print(vocab_sorter) #sorted indizes \n",
    "#print(vocab[vocab_sorter]) #outputs sorted vocabulary\n",
    "\n",
    "ndocs = len(docpaths)\n",
    "nvocab = len(vocab)\n",
    "\n",
    "#Initialize components of COO-Matrix (values, row indizes, col indizes) with emtpy values (for all non-zero elements)\n",
    "data = np.empty(n_nonzero, dtype=np.float32)     # all non-zero term frequencies at data[i,k]\n",
    "rows = np.empty(n_nonzero, dtype=np.intc)     # row index for [i,k]th data item (ith term freq.)\n",
    "cols = np.empty(n_nonzero, dtype=np.intc)     # column index for [i,k]th data item (kth document)\n",
    "\n",
    "#Init index (w.r.t. position in arrays of sparse COO matrix)\n",
    "ind = 0   \n",
    "global_indices = []\n",
    "# go through all documents with their terms\n",
    "for docpath, terms in docs.items():\n",
    "    # find indices into  such that, if the corresponding elements in  were\n",
    "    # inserted before the indices, the order of  would be preserved\n",
    "    # -> array of indices of  in \n",
    "    term_indices = vocab_sorter[np.searchsorted(vocab, terms, sorter=vocab_sorter)]\n",
    "\n",
    "    # count the unique terms of the document and get their vocabulary indices\n",
    "    uniq_indices, counts = np.unique(term_indices, return_counts=True)\n",
    "    \n",
    "    # add (unique) indices of current doc to a list which is later on used for df\n",
    "    global_indices.extend(uniq_indices)\n",
    "    \n",
    "    n_vals = len(uniq_indices)  # = number of unique terms\n",
    "    ind_end = ind + n_vals  #  to  is the slice that we will fill with data\n",
    "\n",
    "    data[ind:ind_end] = counts                  # save the counts (term frequencies)\n",
    "    rows[ind:ind_end] = uniq_indices            # save the row index: index in \n",
    "    doc_idx = np.where(docpaths == docpath)     # get the document index for the document name\n",
    "    cols[ind:ind_end] = np.repeat(doc_idx, n_vals)  # save it as repeated value\n",
    "\n",
    "    ind = ind_end  # resume with next document -> add data to the end\n",
    "\n",
    "#calculate the term df by counting the occurence of the unqiue indices per document -> result is sorted by index\n",
    "global_unique_indices, global_counts = np.unique(global_indices, return_counts=True)\n",
    "\n",
    "#calculation of idf\n",
    "idf = ndocs/global_counts\n",
    "\n",
    "#select idf according to indices in \"rows\" vector for DTM and multiply it with \"data\"(tf) vector -> tf-idf\n",
    "data = np.multiply(data,idf[rows])\n",
    "\n",
    "#Construct DTM as COO Matrix\n",
    "dtm = coo_matrix((data, (rows, cols)), shape=(nvocab, ndocs), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dtm.toarray())\n",
    "print(vocab)\n",
    "print(docpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "\n",
    "U, s, V = svds(dtm.asfptype(), k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    self.tdm = load_npz(loadPath + \"tfidf.tdm\")\n",
    "\n",
    "    self.docpaths = np.load(loadPath + \"tfidf.docs\")\n",
    "    self.vocab = np.load(loadPath + \"tfidf.vocab\")\n",
    "    self.idf= np.load(loadPath + \"tfidf.idf\")\n",
    "\n",
    "except:\n",
    "    print(\"TF-IDF: Load from file failed - \", sys.exc_info()[0])\n",
    "    exc = sys.exc_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = dtm.toarray()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = (inv(np.diag(s)).dot(U.transpose())).dot(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = (V.transpose().dot(dv))/(np.sqrt(np.diag(V.transpose().dot(V)))*norm(dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.apply_along_axis( myfunction, axis=1, arr=mymatrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(V.transpose()**2,axis=-1)**(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in np.nditer(V):\n",
    "    print(norm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorter = np.argsort(sim)[::-1]\n",
    "sim[sorter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = ['ein','ein','weiteres','Dokument']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [np.where(vocab==item) for i, item in enumerate(doc) if item in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [np.where(vocab == item) for i, item in enumerate(doc) if item in vocab]\n",
    "indices_unique, counts = np.unique(indices, return_counts=True)\n",
    "vec = np.empty(len(vocab), dtype=np.float32)\n",
    "vec[indices_unique] = counts * idf[indices_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(doc in vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import svd, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, s, V = svd(dtm.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,k+2),s, 'bo')\n",
    "plt.axis([1, k, 0, s.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv(np.diag(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U.dot(np.diag(s)).dot(V.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, load_npz\n",
    "saved_tdm = load_npz(\"../lib/files/tfidf.tdm.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_tdm.toarray()[1:100,1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U, s, V = svds(saved_tdm.asfptype(), k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../lib/files/bow.dict\", 'r') as infile:\n",
    "    docs = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key in docs.keys():\n",
    "    if(i> 30 ):\n",
    "        break\n",
    "    print(len(docs.get(key)))\n",
    "    i+= 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs.get('sci.space/59848')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs.get('sci.electronics/52434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = np.load(\"../lib/files/\" + \"svd.s.npy\")\n",
    "Ut = np.load(\"../lib/files/\" + \"svd.Ut.npy\")\n",
    "V = np.load(\"../lib/files/\" + \"svd.V.npy\")\n",
    "k = np.load(\"../lib/files/\" + \"svd.k.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SiUt = inv(np.diag(s)).dot(Ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (30,30) (30,150447) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-518f7c52aa24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSiUt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mUt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (30,30) (30,150447) "
     ]
    }
   ],
   "source": [
    "SiUt = inv(np.diag(s)) * (Ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 150447)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiUt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ut.transpose()[:,100:201].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vt.transpose()[100:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 199\n",
    "plt.plot(range(1,k+1),s[::-1], 'bo')\n",
    "plt.axis([1, k, 0, s.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Uk, sk, Vk = svds(saved_tdm.asfptype(), k=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Uk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min = np.min(s.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sn = np.diag(s[min:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Un = Ut.transpose()[:,min:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vtn = Vt.transpose()[min:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv(Sn).dot(Un.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(saved_tdm.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the histogram of the data\n",
    "plt.hist(saved_tdm.data)\n",
    "plt.title(\"Histogram\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_tdm.data == min(saved_tdm.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_tdm.row[saved_tdm.data == max(saved_tdm.data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = np.load(\"../lib/files/\" + \"tfidf.vocab.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab[saved_tdm.row[saved_tdm.data >= (max(saved_tdm.data)/10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(saved_tdm.data[saved_tdm.data >= (max(saved_tdm.data)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [10,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "math.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
